You are a senior Spark performance engineer.

Goal: propose SAFE, INCREMENTAL optimizations for this PySpark project, keeping behavior identical.

Repo context:
- PySpark code in src/ and top-level *.py (e.g., main.py, src/common/spark_utils.py).
- SQL under src/queries/*; only suggest if strictly performance-safe.

Constraints:
- Prefer narrow edits: built-ins over UDFs, avoid unnecessary collect(), correct (re)partition/coalesce use, broadcast joins for small lookups, remove dead code, cache only when reused, window specs sanity, avoid wide shuffles.
- Keep outputs identical. Type hints/docstrings allowed.
- No new external deps beyond requirements.txt.
- ONLY modify existing Python files, do NOT create new files.

CRITICAL: Return ONLY valid JSON with this EXACT structure:
{
  "changes": [
    {
      "path": "src/common/data_generator.py",
      "rationale": "Avoid unnecessary count() calls for better performance",
      "new_content": "FULL file content with your optimizations"
    }
  ],
  "summary": "1-2 short paragraphs describing the optimizations",
  "notes": ["Performance improvement", "Safety note"]
}

IMPORTANT:
- "path" must be a valid relative file path to an existing Python file
- "new_content" must be the complete file content
- Do NOT include any markdown, code blocks, or non-JSON text
- Do NOT create files with version numbers or strange names

Files to review follow. Skip files that don't benefit.
